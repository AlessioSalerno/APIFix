Configuration: 
---- UseAdditionalOutput: True
---- UseAdditionalInput : False
---- OnlyNewUsage       : False
---- GivenExample       : 1
---- UseTypedUsage      : False
---- NewKeyWords        : 
---- OldKeyWords        : 
---- OldUsageThreashold : 0.15
---- NewUsageThreashold : 0.25
---- Validate           : True
load 3 relevant edits!
load 592 new relevant usages
loading D:\workspace\breaking-changes\benchmark\Polly\Polly_6.1.2_7.0.0\clients\CalculateFunding-Common
loading D:\workspace\breaking-changes\benchmark\Polly\Polly_6.1.2_7.0.0\clients\MS.DotNetCore.App
loading D:\workspace\breaking-changes\benchmark\Polly\Polly_6.1.2_7.0.0\clients\ServiceFabricGateway
load 5 relevant client edits!
Log: invoke synthesis engine...
Log: the size of unRolledEdits is: 3
size of new usage: 592
Log: add new usage var arr = new IAsyncPolicy[] { Policy.Handle < HttpRequestException >().WaitAndRetryAsync(_retryCount, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => { var msg = $"Retry {retryCount} implemented with Polly's RetryPolicy " + $"of {context.PolicyKey}" + $"at {context.OperationKey}, " + $"due to: {exception}."; _logger.LogWarning(msg); _logger.LogDebug(msg); }), Policy.Handle < HttpRequestException >().CircuitBreakerAsync(_exceptionCountAllowedBeforeBreaking, TimeSpan.FromMinutes(1),(exception, duration) => { _logger.LogTrace("Circuit breaker opened"); },() => { _logger.LogTrace("Circuit breaker reset"); }) };
Log: add new usage var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(50, retryAttempt => TimeSpan.FromSeconds(1),(exception, timeSpan, retryCount, context) => { });
Log: add new usage var retryGetSubLanguagesPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retrySearchSubtitlesFromImdbPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retryDownloadSubtitleToPathPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicyForError596 = Policy.Handle < SqlException >(x => x.Number == 596).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5 + retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == -2 || x.Number == 1205).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromMilliseconds(200 * retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
Log: add new usage var waitAndRetryPolicyForError596 = Policy.Handle < SqlException >(x => x.Number == 596).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5 + retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == 1205).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromMilliseconds(200 * retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == 983 || x.Number == 978).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5 + retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { _logger.LogInformation(exception, "Open Connection - DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.HandleResult < LockLeaseResult >(lockLeaseResult => ! lockLeaseResult.Ok).WaitAndRetryAsync(retryCount, retryAttempt => TimeSpan.FromSeconds(retryAfter));
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => { });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(NumberOfRetries, attempt => TimeSpan.FromMilliseconds(200),(exception, calculatedWaitDuration) => { _logger.LogError($"Could not replicate - exception {exception.Message}"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var falseResultPolicy = Policy.HandleResult(false).WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(result, _) => OnRetry());
Log: add new usage var exceptionPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r => r.StatusCode ==(HttpStatusCode) 429).WaitAndRetryAsync(retryCount : MaxRetries, sleepDurationProvider :(retryCount, response, context) => { return response.Result ?.Headers.RetryAfter.Delta.Value ?? TimeSpan.FromSeconds(30 * retryCount); }, onRetryAsync : async(response, timespan, retryCount, context) => { await Console.Out.WriteLineAsync($"{Environment.NewLine}Waiting {timespan} before retrying (attemp #{retryCount}/{MaxRetries})..."); });
Log: add new usage var retryPolicy = Policy.Handle < AdalServiceException >().WaitAndRetryAsync(MAX_TOKEN_RETRY_ATTEMPTS, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryWithJitterPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound).WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(jitterer.Next(0, 100)));
Log: add new usage AsyncRetryPolicy < HttpResponseMessage > retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(r => r.StatusCode == HttpStatusCode.NotFound).WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) },(x, i) => x.Result.Dispose());
Log: add new usage var retryAndExitPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var policy = Policy.Handle < Exception >(e => { Console.WriteLine("Tentando obter Token"); return true; }).WaitAndRetryAsync(3, i => TimeSpan.FromTicks(5));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
Log: add new usage var policy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1));
Log: add new usage var policy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(x => x.StatusCode == HttpStatusCode.BadRequest).WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1));
Log: add new usage var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
Log: add new usage var retryGetSubLanguagesPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retrySearchSubtitlesFromImdbPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retryDownloadSubtitleToPathPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < SoapException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => Logger.Error(exception, "Служба СМС вернула ошибку. Код: {code}. Сообщение: {message}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount}", exception.HResult, exception.Message, timeSpan, retryCount));
Log: add new usage var waitAndRetryPolicy = Policy.HandleResult < DeliveryStatus >(status => status != DeliveryStatus.Delivered).WaitAndRetryAsync(11, retryAttempt => TimeSpan.FromSeconds(10 * retryAttempt),(result, timeSpan, retryCount, context) => Logger.Info("Сообщение {messageId} для заявки {appId} клиента {userName} не доставлено. Текущий статус отправки {status}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount}", messageId, applicationId, userName ?? "",((SmsDeliveryStatus) result.Result).GetDescription(), timeSpan, retryCount));
Log: add new usage var waitAndRetryPolicy = Policy.HandleResult < HttpResponseMessage >(message => ! message.IsSuccessStatusCode).WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) },(result, timeSpan, retryCount, context) => Logger.Error(result.Exception, "Запрос к сервису статистики неудачен. Код: {statusCode}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount} {request}", result.Result.StatusCode, timeSpan, retryCount, requestContent));
Log: add new usage var waitAndRetryPolicy = Policy.HandleResult < ClientValidationRequest >(result => result ?.Result ==(int) ClientValidationResult.Requested).WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.Handle < HttpRequestException >().OrResult < bool >(result => result == false).WaitAndRetryAsync(RetryCount, i => TimeSpan.FromSeconds(WaitSecondsBeforeRetry));
Log: add new usage AsyncRetryPolicy < HttpResponseMessage > retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(r => r.StatusCode == HttpStatusCode.NotFound).WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) },(x, i) => x.Result.Dispose());
Log: add new usage var retryAndExitPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(retriesCount, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan) => { logger.LogError(exception, $"Operation failed, retrying in {timeSpan.Seconds} seconds"); });
Log: add new usage var retryGetSubLanguagesPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retrySearchSubtitlesFromImdbPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retryDownloadSubtitleToPathPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryFailedUserPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var policy = Policy.Handle < ResponseException >().Or < ConnectionPoolBusyException >().Or < ServerUnavailableException >().WaitAndRetryAsync(retryCount : 10, sleepDurationProvider :(attempt, exception, context) => { if(exception is ResponseException responseException && responseException.CosmosDbStatusCode() == RetryAfterStatusCode) { return TimeSpan.FromSeconds(5 + 5 * attempt * _jitterer.NextDouble()); } _logger.LogInformation($"Exception {exception.GetType()}. Retry immediately"); return TimeSpan.Zero; }, onRetryAsync :(exception, waitTime, attempt, _) => { totalWaitTime = totalWaitTime.Add(waitTime); retryCount = attempt; if(exception is ResponseException responseException) { var exceptionRu = CosmosResponse.ParseRequestCharge(responseException.StatusAttributes); totalRu += exceptionRu; _logger.LogInformation($"ResponseException cost {exceptionRu}RU"); } if(exception is ConnectionPoolBusyException || exception is ServerUnavailableException) { _logger.LogInformation($"Resetting the GremlinClient after experiencing an '{exception.GetType()}'"); _factory.ClearGraphClient(); } return Task.CompletedTask; });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryFailedUserPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
Log: add new usage var policyRegistry = new PolicyRegistry { { RetryPolicyKey.NoRetry.ToString(), Policy.NoOpAsync() }, { RetryPolicyKey.BasicRetryOnRpc.ToString(), Policy.Handle < RpcException >().RetryAsync(MaxRetries,(exception, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { RetryPolicyKey.RetryOnRpcWithExponentialBackoff.ToString(), Policy.Handle < RpcException >().WaitAndRetryAsync(Backoff.ExponentialBackoff(TimeSpan.FromSeconds(1), MaxRetries),(exception, timeSpan, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; TimeSpan: {timeSpan.ToString()}. Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { RetryPolicyKey.RetryOnRpcWithJitter.ToString(), Policy.Handle < RpcException >().WaitAndRetryAsync(MaxRetries, retryAttempt => { var backoffSpans = Backoff.DecorrelatedJitterBackoffV2(TimeSpan.FromSeconds(1), MaxRetries).ToList(); return backoffSpans[retryAttempt - 1]; },(exception, timeSpan, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; TimeSpan: {timeSpan.ToString()}. Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { CachePolicyKey.InMemoryCache.ToString(), Policy.CacheAsync(componentContext.Resolve < IAsyncCacheProvider >(), TimeSpan.FromMinutes(5),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache get {cacheKey}"),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache miss {cacheKey}"),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache put {cacheKey}"),(policyContext, cacheKey, exception) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache get error {cacheKey}; {exception}"),(policyContext, cacheKey, exception) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache put error {cacheKey}; {exception}")) }, { CachePolicyKey.NoCache.ToString(), Policy.NoOpAsync() }, { TimeoutPolicyKey.NoTimeout.ToString(), Policy.NoOpAsync() }, { TimeoutPolicyKey.DefaultPessimisticTimeout.ToString(), Policy.TimeoutAsync(TimeSpan.FromMilliseconds(500), TimeoutStrategy.Pessimistic,(context, span, task) => { task.ContinueWith(t => { if(t.IsFaulted) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, eventually terminated with: {t.Exception.Message}."); } else if(t.IsCanceled) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task cancelled."); } else { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task completed."); } }); console.Out.WriteLine($"Operation {context.OperationKey} timed out."); return Task.CompletedTask; }) }, { TimeoutPolicyKey.DefaultOptimisticTimeout.ToString(), Policy.TimeoutAsync(TimeSpan.FromMilliseconds(500), TimeoutStrategy.Optimistic,(context, span, abandonedTask) => { console.Out.WriteLine($"Operation: {context.OperationKey}, timeout after {span}. "); abandonedTask.ContinueWith(t => { if(t.IsFaulted) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, eventually terminated with: {t.Exception.Message}."); } else if(t.IsCanceled) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task cancelled."); } else { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task completed."); } }); return Task.CompletedTask; }) }, { CircuitBreakerPolicyKey.NoBreaker.ToString(), Policy.NoOpAsync() }, { CircuitBreakerPolicyKey.DefaultCircuitBreaker.ToString(), Policy.Handle < RpcException >().CircuitBreakerAsync(2, TimeSpan.FromSeconds(2),(exception, span) => { console.WriteLine($"Circuit broken. Span: {span}; Exception: {exception.Message};"); },() => { console.WriteLine("Circuit reset."); },() => { console.WriteLine("Circuit half openBa."); }) }, };
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolice = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
Log: add new usage var retryPolity = Policy.Handle < Exception >().WaitAndRetryAsync(maxtrys, x => seconds);
Log: add new usage var retryWithJitterPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.GatewayTimeout || msg.StatusCode == System.Net.HttpStatusCode.ServiceUnavailable).WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(jitterer.Next(0, 100)));
Log: add new usage var policy = Policy.Handle < HttpRequestException >().Or < OperationCanceledException >().WaitAndRetryAsync(retryCount, i => TimeSpan.FromSeconds(delayAfterFailure));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(10));
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(r => r.StatusCode == HttpStatusCode.NotFound).WaitAndRetryAsync(policyConfigs.RetryCount, _ => TimeSpan.FromMilliseconds(policyConfigs.RetryDelayInMs));
Log: add new usage var httpRetryPolicy = Policy.Handle < HttpRequestException >().Or < TaskCanceledException >().Or < TimeoutRejectedException >().OrResult < HttpResponseMessage >(RetryRequired).WaitAndRetryAsync(GetBackOff(maxRetries));
Log: add new usage var retryAfterPolicy = Policy.HandleResult < HttpResponseMessage >(ContainsRetryAfterHeader).WaitAndRetryAsync(maxRetries, sleepDurationProvider,(outcome, timespan, retryCount, context) => Task.CompletedTask);
Log: add new usage var retryPolicy = HandleResult().Or < TimeoutRejectedException >().WaitAndRetryAsync(retryCount, retryAttempt => retryDelay);
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(6, attempt => TimeSpan.FromSeconds(0.1 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { Console.WriteLine($"{exception.Message} : Auto delay for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(20, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(3, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(6, attempt => TimeSpan.FromSeconds(0.1 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { Console.WriteLine($"{exception.Message} : Auto delay for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(20, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(3, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
Log: add new usage AsyncRetryPolicy < HttpResponseMessage > retryAndSleepPolicy = Policy.HandleResult < HttpResponseMessage >(r => ShoulRetryOnHttpResponse(r)).WaitAndRetryAsync(retryCount : retryConfiguration.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(retryConfiguration.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryAttempt, context) => { logger.Info($"Retry Attempt: {retryAttempt}"); await Task.CompletedTask; });
Log: add new usage var retryAndSleepPolicy = Policy.HandleResult < Response >(response => ! this.condition(response)).WaitAndRetryAsync(retryCount : waiterConfig.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(waiterConfig.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryCount, context) => { logger.Trace($"Retry Attempt: {retryCount}"); await Task.CompletedTask; });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retry = Policy.Handle < Exception >().WaitAndRetryAsync(Backoff.LinearBackoff(TimeSpan.FromSeconds(settings.RetryInitialDelaySeconds), settings.RetryCount),(exception, span, retryCount, context) => { logger.LogError(exception, "{@EventType} {@Realm} {@TimeSpan} {@retryCount}", "Retry", description, span, retryCount); });
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) },(exception, timeSpan, retryCount, context) => { });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage var falseResultPolicy = Policy.HandleResult(false).WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(result, _) => OnRetry());
Log: add new usage var exceptionPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(retryCount : retries, sleepDurationProvider : x => TimeSpan.FromSeconds(5), onRetry :(exception, timeSpan, retry, context) => { logger.LogWarning(exception, "[{prefix}] Exception {ExceptionType} with message {Message} detected on attempt {retry} of {retries}", prefix, exception.GetType().Name, exception.Message, retry, retries); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolity = Policy.Handle < Exception >().WaitAndRetryAsync(maxtrys, x => seconds);
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage IAsyncPolicy < HttpResponseMessage > policy = Policy.Handle < SocketException >().OrTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var retryWhenServiceUnavailable = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.ServiceUnavailable).WaitAndRetryAsync(1, retryAttempt => TimeSpan.FromSeconds(10));
Log: add new usage var retryWhenTimeout = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.RequestTimeout).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5));
Log: add new usage var retryWhenThrottling = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.TooManyRequests).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(5, retryAttempt)));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retry = Policy < HttpResponseMessage >.Handle < Exception >().WaitAndRetryAsync(3, i => TimeSpan.FromSeconds(1));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < InvalidOperationException >().Or < Exception >().WaitAndRetryAsync(_retryCount, retryAttempt => TimeSpan.FromSeconds(1),(ex, time) => { _logger.LogWarning(ex.ToString()); });
Log: add new usage var policy = Policy.Handle < InvalidOperationException >().Or < Exception >().WaitAndRetryAsync(_retryCount, retryAttempt => TimeSpan.FromSeconds(1),(ex, time) => { _logger.LogWarning(ex.ToString()); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, i => TimeSpan.FromSeconds(1));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage AsyncRetryPolicy < HttpResponseMessage > retryAndSleepPolicy = Policy.HandleResult < HttpResponseMessage >(r => ShoulRetryOnHttpResponse(r)).WaitAndRetryAsync(retryCount : retryConfiguration.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(retryConfiguration.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryAttempt, context) => { logger.Info($"Retry Attempt: {retryAttempt}"); await Task.CompletedTask.ConfigureAwait(false); });
Log: add new usage var retryAndSleepPolicy = Policy.HandleResult < Response >(response => ! this.condition(response)).WaitAndRetryAsync(retryCount : waiterConfig.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(waiterConfig.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryCount, context) => { logger.Trace($"Retry Attempt: {retryCount}"); await Task.CompletedTask.ConfigureAwait(false); });
Log: add new usage var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(retryCount : retries, sleepDurationProvider : x => TimeSpan.FromSeconds(5), onRetry :(exception, timeSpan, retry, context) => { logger.LogWarning(exception, "[{prefix}] Exception {ExceptionType} with message {Message} detected on attempt {retry} of {retries}", prefix, exception.GetType().Name, exception.Message, retry, retries); });
Log: add new usage var policyRetry = Policy.Handle < InvalidOperationException >().WaitAndRetryAsync(3, retryTimespan => TimeSpan.FromSeconds(Math.Pow(2, retryTimespan)),(exception, timespan, retryCount, context) => { var msg = $"第 {retryCount} 次进行错误重试 " + $"of {context.PolicyKey}" + $"at {context.OperationKey}, " + $"due to: {exception}."; _logger.LogWarning(msg); _logger.LogDebug(msg); });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < Exception >().OrResult < HttpResponseMessage >(e => HttpStatusCodeWorthRetry.ToList().Contains((int) e.StatusCode)).WaitAndRetryAsync(MaxRetryCount, attempt => TimeSpan.FromSeconds(1 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => PolicyLog($"API is throttling our requests automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"));
Log: add new usage var policy = Policy.Handle < Exception >().OrResult < HttpResponseMessage >(r => ! r.IsSuccessStatusCode).WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(1000));
Log: add new usage var policy = Policy.Handle < Exception >().OrResult < HttpResponseMessage >(r => ! r.IsSuccessStatusCode).WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(1000));
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage AsyncRetryPolicy retryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var polly = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, pause => TimeSpan.FromSeconds(5));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r => r.StatusCode != HttpStatusCode.OK).WaitAndRetryAsync(_appSettings.RetryAttempt, retryAttempt => TimeSpan.FromMilliseconds(3000));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.HandleResult < IRestResponse >(x => FindWarning(x) is null && x.StatusCode != HttpStatusCode.NotFound && x.StatusCode != HttpStatusCode.Unauthorized && x.StatusCode != HttpStatusCode.Conflict && x.StatusCode != HttpStatusCode.BadRequest && x.StatusCode != HttpStatusCode.OK).WaitAndRetryAsync(retryNumber, retryAttempt => TimeSpan.FromSeconds(retrySleepSeconds));
Log: add new usage var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Trying for the {retryCount} time!"); Console.ForegroundColor = ConsoleColor.White; });
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, x => TimeSpan.FromSeconds(1),(result, span) => { });
Log: add new usage var policy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, x => TimeSpan.FromSeconds(1),(result, span) => { });
Log: add new usage var retryPolicy = Policy.HandleResult < HttpResponseMessage >(r => ! r.IsSuccessStatusCode).WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(1),(result, span, retryCount, ctx) => { Console.WriteLine($"Retrying({retryCount})..."); });
Log: add new usage var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
Log: add new usage var retryPolicy = Policy.Handle < HttpRequestException >().Or < Exception >().OrResult < HttpResponseMessage >(res => { return res.StatusCode != System.Net.HttpStatusCode.OK; }).WaitAndRetryAsync(sleepDurations : new[] { TimeSpan.FromMilliseconds(100), TimeSpan.FromMilliseconds(200), TimeSpan.FromMilliseconds(300) }, onRetry :(exception, ts, context) => { Console.WriteLine($"polly.retry：exMsg={exception.Exception ?.Message}, {ts.Minutes * 60 + ts.Seconds}"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryWaitPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = Policy.Handle < HttpRequestException >().Or < TimeoutException >().Or < TimeoutRejectedException >().WaitAndRetryAsync(retryCount : 2, sleepDurationProvider : retryAttempt => { var waitSeconds = TimeSpan.FromSeconds(Math.Pow(2, retryAttempt - 1)); Console.WriteLine(DateTime.Now.ToString() + "-Retry:[" + retryAttempt + "], wait " + waitSeconds + "s!"); return waitSeconds; });
Log: add new usage var policy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, retryAttempt => { var waitSeconds = TimeSpan.FromSeconds(Math.Pow(2, retryAttempt - 1)); Console.WriteLine(DateTime.Now.ToString() + "-Retry:[" + retryAttempt + "], wait " + waitSeconds + "s..."); return waitSeconds; });
Log: add new usage var retryPolicy = Policy.Handle < Exception >((ex) => { logger.Log(LogSeverity.Error,(ex.InnerException != null) ? ex.InnerException.Message : ex.Message + "\r\n GetTrendingStocks retry FAILURE"); return !(ex is Polly.CircuitBreaker.BrokenCircuitException); }).WaitAndRetryAsync(_retryCount, x => TimeSpan.FromMilliseconds(_sleepTimeAfterFail));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var retryPolice = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
Log: add new usage var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
Log: add new usage var policy = Policy.Handle < SentNotificationException >().WaitAndRetryAsync(_maxRetryAttempts, retryAttempt => TimeSpan.FromSeconds(Math.Pow(3, retryAttempt)));
Log: add new usage var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
Log: add new usage var retryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r =>(int) r.StatusCode == 429).WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add new usage var retryPolicy = Policy.Handle < System.Net.Sockets.SocketException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
Log: add old usage RetryPolicy retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, context) => { _logger.LogWarning(exception, "Retrying to write config"); });
Log: ============== Cluster start ==============
- Policy policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds(),
                    2.Seconds(),
                    3.Seconds()
                }, (_, __, context) => contextData = context);
----------------
+ var policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds(),
                    2.Seconds(),
                    3.Seconds()
                }, (_, __, context) => contextData = context);

- Policy policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds(),
                    2.Seconds(),
                    3.Seconds()
                }, (_, __, context) => capturedContext = context);
----------------
+ var policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds(),
                    2.Seconds(),
                    3.Seconds()
                }, (_, __, context) => capturedContext = context);

- Policy policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds()
                },
                (_, __, context) => contextValue = context["key"].ToString());
----------------
+ var policy = Policy
                .Handle<DivideByZeroException>()
                .WaitAndRetryAsync(new[]
                {
                    1.Seconds()
                },
                (_, __, context) => contextValue = context["key"].ToString());

new usages: var arr = new IAsyncPolicy[] { Policy.Handle < HttpRequestException >().WaitAndRetryAsync(_retryCount, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => { var msg = $"Retry {retryCount} implemented with Polly's RetryPolicy " + $"of {context.PolicyKey}" + $"at {context.OperationKey}, " + $"due to: {exception}."; _logger.LogWarning(msg); _logger.LogDebug(msg); }), Policy.Handle < HttpRequestException >().CircuitBreakerAsync(_exceptionCountAllowedBeforeBreaking, TimeSpan.FromMinutes(1),(exception, duration) => { _logger.LogTrace("Circuit breaker opened"); },() => { _logger.LogTrace("Circuit breaker reset"); }) };
new usages: var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
new usages: var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(50, retryAttempt => TimeSpan.FromSeconds(1),(exception, timeSpan, retryCount, context) => { });
new usages: var retryGetSubLanguagesPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var retrySearchSubtitlesFromImdbPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var retryDownloadSubtitleToPathPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(new Random(Guid.NewGuid().GetHashCode()).Next(0, 1000)));
new usages: var waitAndRetryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(e => e.StatusCode == HttpStatusCode.ServiceUnavailable || e.StatusCode ==(System.Net.HttpStatusCode) 429 || e.StatusCode ==(System.Net.HttpStatusCode) 403).WaitAndRetryAsync(10, attempt => TimeSpan.FromSeconds(0.25 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { _log.LogWarning($"Computer Vision API server is throttling our requests. Automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"); });
new usages: var waitAndRetryPolicyForError596 = Policy.Handle < SqlException >(x => x.Number == 596).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5 + retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
new usages: var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == -2 || x.Number == 1205).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromMilliseconds(200 * retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
new usages: var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == 1205).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromMilliseconds(200 * retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { var sql = context.ContainsKey("sql") ? context["sql"] : ""; using(_logger.BeginScope(new Dictionary < string, object > {["sql"] = sql })) _logger.LogInformation(exception, "DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
new usages: var waitAndRetryPolicy = Policy.Handle < SqlException >(x => x.Number == 983 || x.Number == 978).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5 + retryAttempt), onRetry :(exception, calculatedWaitDuration, retryCount, context) => { _logger.LogInformation(exception, "Open Connection - DB Retry {RetryCount} occurred after {timeSpan}", retryCount, calculatedWaitDuration); });
new usages: var policy = Policy.HandleResult < LockLeaseResult >(lockLeaseResult => ! lockLeaseResult.Ok).WaitAndRetryAsync(retryCount, retryAttempt => TimeSpan.FromSeconds(retryAfter));
new usages: var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => { });
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(NumberOfRetries, attempt => TimeSpan.FromMilliseconds(200),(exception, calculatedWaitDuration) => { _logger.LogError($"Could not replicate - exception {exception.Message}"); });
new usages: var falseResultPolicy = Policy.HandleResult(false).WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(result, _) => OnRetry());
new usages: var exceptionPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(retryCount, _ => TimeSpan.FromSeconds(ReconnectIntervalSec),(exc, _) => OnRetry(exc));
new usages: var policy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r => r.StatusCode ==(HttpStatusCode) 429).WaitAndRetryAsync(retryCount : MaxRetries, sleepDurationProvider :(retryCount, response, context) => { return response.Result ?.Headers.RetryAfter.Delta.Value ?? TimeSpan.FromSeconds(30 * retryCount); }, onRetryAsync : async(response, timespan, retryCount, context) => { await Console.Out.WriteLineAsync($"{Environment.NewLine}Waiting {timespan} before retrying (attemp #{retryCount}/{MaxRetries})..."); });
new usages: var retryPolicy = Policy.Handle < AdalServiceException >().WaitAndRetryAsync(MAX_TOKEN_RETRY_ATTEMPTS, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var retryWithJitterPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.NotFound).WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(jitterer.Next(0, 100)));
new usages: AsyncRetryPolicy < HttpResponseMessage > retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(r => r.StatusCode == HttpStatusCode.NotFound).WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) },(x, i) => x.Result.Dispose());
new usages: var retryAndExitPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
new usages: var retryPolicy = Policy.Handle < ArgumentException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
new usages: var policy = Policy.Handle < Exception >(e => { Console.WriteLine("Tentando obter Token"); return true; }).WaitAndRetryAsync(3, i => TimeSpan.FromTicks(5));
new usages: var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), TimeSpan.FromSeconds(15), },(ext, timeSpan, retryCount, context) => { _logger.LogError(ext, $"Error - try retry (count: {retryCount}, timeSpan: {timeSpan})"); });
new usages: var policy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1));
new usages: var policy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(x => x.StatusCode == HttpStatusCode.BadRequest).WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(1));
new usages: var waitAndRetryPolicy = Policy.Handle < SoapException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, retryCount, context) => Logger.Error(exception, "Служба СМС вернула ошибку. Код: {code}. Сообщение: {message}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount}", exception.HResult, exception.Message, timeSpan, retryCount));
new usages: var waitAndRetryPolicy = Policy.HandleResult < DeliveryStatus >(status => status != DeliveryStatus.Delivered).WaitAndRetryAsync(11, retryAttempt => TimeSpan.FromSeconds(10 * retryAttempt),(result, timeSpan, retryCount, context) => Logger.Info("Сообщение {messageId} для заявки {appId} клиента {userName} не доставлено. Текущий статус отправки {status}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount}", messageId, applicationId, userName ?? "",((SmsDeliveryStatus) result.Result).GetDescription(), timeSpan, retryCount));
new usages: var waitAndRetryPolicy = Policy.HandleResult < HttpResponseMessage >(message => ! message.IsSuccessStatusCode).WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) },(result, timeSpan, retryCount, context) => Logger.Error(result.Exception, "Запрос к сервису статистики неудачен. Код: {statusCode}. Время ожидания до следующей попытки: {timeSpan}. Попытка: {retryCount} {request}", result.Result.StatusCode, timeSpan, retryCount, requestContent));
new usages: var waitAndRetryPolicy = Policy.HandleResult < ClientValidationRequest >(result => result ?.Result ==(int) ClientValidationResult.Requested).WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var retryPolicy = Policy.Handle < HttpRequestException >().OrResult < bool >(result => result == false).WaitAndRetryAsync(RetryCount, i => TimeSpan.FromSeconds(WaitSecondsBeforeRetry));
new usages: var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(retriesCount, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan) => { logger.LogError(exception, $"Operation failed, retrying in {timeSpan.Seconds} seconds"); });
new usages: var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
new usages: var retryFailedUserPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxNumberOfAttempts, p => TimeSpan.FromSeconds(p));
new usages: var policy = Policy.Handle < ResponseException >().Or < ConnectionPoolBusyException >().Or < ServerUnavailableException >().WaitAndRetryAsync(retryCount : 10, sleepDurationProvider :(attempt, exception, context) => { if(exception is ResponseException responseException && responseException.CosmosDbStatusCode() == RetryAfterStatusCode) { return TimeSpan.FromSeconds(5 + 5 * attempt * _jitterer.NextDouble()); } _logger.LogInformation($"Exception {exception.GetType()}. Retry immediately"); return TimeSpan.Zero; }, onRetryAsync :(exception, waitTime, attempt, _) => { totalWaitTime = totalWaitTime.Add(waitTime); retryCount = attempt; if(exception is ResponseException responseException) { var exceptionRu = CosmosResponse.ParseRequestCharge(responseException.StatusAttributes); totalRu += exceptionRu; _logger.LogInformation($"ResponseException cost {exceptionRu}RU"); } if(exception is ConnectionPoolBusyException || exception is ServerUnavailableException) { _logger.LogInformation($"Resetting the GremlinClient after experiencing an '{exception.GetType()}'"); _factory.ClearGraphClient(); } return Task.CompletedTask; });
new usages: var policyRegistry = new PolicyRegistry { { RetryPolicyKey.NoRetry.ToString(), Policy.NoOpAsync() }, { RetryPolicyKey.BasicRetryOnRpc.ToString(), Policy.Handle < RpcException >().RetryAsync(MaxRetries,(exception, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { RetryPolicyKey.RetryOnRpcWithExponentialBackoff.ToString(), Policy.Handle < RpcException >().WaitAndRetryAsync(Backoff.ExponentialBackoff(TimeSpan.FromSeconds(1), MaxRetries),(exception, timeSpan, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; TimeSpan: {timeSpan.ToString()}. Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { RetryPolicyKey.RetryOnRpcWithJitter.ToString(), Policy.Handle < RpcException >().WaitAndRetryAsync(MaxRetries, retryAttempt => { var backoffSpans = Backoff.DecorrelatedJitterBackoffV2(TimeSpan.FromSeconds(1), MaxRetries).ToList(); return backoffSpans[retryAttempt - 1]; },(exception, timeSpan, retryAttempt, context) => { console.Out.WriteLine($"Operation: {context.OperationKey}; TimeSpan: {timeSpan.ToString()}. Attempt {retryAttempt - 1} failed: {exception.Message}. Retrying."); return Task.CompletedTask; }) }, { CachePolicyKey.InMemoryCache.ToString(), Policy.CacheAsync(componentContext.Resolve < IAsyncCacheProvider >(), TimeSpan.FromMinutes(5),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache get {cacheKey}"),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache miss {cacheKey}"),(policyContext, cacheKey) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache put {cacheKey}"),(policyContext, cacheKey, exception) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache get error {cacheKey}; {exception}"),(policyContext, cacheKey, exception) => console.WriteLine($"Operation {policyContext.OperationKey}: Cache put error {cacheKey}; {exception}")) }, { CachePolicyKey.NoCache.ToString(), Policy.NoOpAsync() }, { TimeoutPolicyKey.NoTimeout.ToString(), Policy.NoOpAsync() }, { TimeoutPolicyKey.DefaultPessimisticTimeout.ToString(), Policy.TimeoutAsync(TimeSpan.FromMilliseconds(500), TimeoutStrategy.Pessimistic,(context, span, task) => { task.ContinueWith(t => { if(t.IsFaulted) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, eventually terminated with: {t.Exception.Message}."); } else if(t.IsCanceled) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task cancelled."); } else { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task completed."); } }); console.Out.WriteLine($"Operation {context.OperationKey} timed out."); return Task.CompletedTask; }) }, { TimeoutPolicyKey.DefaultOptimisticTimeout.ToString(), Policy.TimeoutAsync(TimeSpan.FromMilliseconds(500), TimeoutStrategy.Optimistic,(context, span, abandonedTask) => { console.Out.WriteLine($"Operation: {context.OperationKey}, timeout after {span}. "); abandonedTask.ContinueWith(t => { if(t.IsFaulted) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, eventually terminated with: {t.Exception.Message}."); } else if(t.IsCanceled) { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task cancelled."); } else { console.Out.WriteLine($"Operation {context.OperationKey}: execution timed out after {span.TotalSeconds} seconds, task completed."); } }); return Task.CompletedTask; }) }, { CircuitBreakerPolicyKey.NoBreaker.ToString(), Policy.NoOpAsync() }, { CircuitBreakerPolicyKey.DefaultCircuitBreaker.ToString(), Policy.Handle < RpcException >().CircuitBreakerAsync(2, TimeSpan.FromSeconds(2),(exception, span) => { console.WriteLine($"Circuit broken. Span: {span}; Exception: {exception.Message};"); },() => { console.WriteLine("Circuit reset."); },() => { console.WriteLine("Circuit half openBa."); }) }, };
new usages: var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(_retries, i => TimeSpan.FromSeconds(_retryInterval));
new usages: var retryPolice = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
new usages: var retryPolity = Policy.Handle < Exception >().WaitAndRetryAsync(maxtrys, x => seconds);
new usages: var retryWithJitterPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(msg => msg.StatusCode == System.Net.HttpStatusCode.GatewayTimeout || msg.StatusCode == System.Net.HttpStatusCode.ServiceUnavailable).WaitAndRetryAsync(6, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(jitterer.Next(0, 100)));
new usages: var policy = Policy.Handle < HttpRequestException >().Or < OperationCanceledException >().WaitAndRetryAsync(retryCount, i => TimeSpan.FromSeconds(delayAfterFailure));
new usages: var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(3, _ => TimeSpan.FromSeconds(10));
new usages: var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().OrResult(r => r.StatusCode == HttpStatusCode.NotFound).WaitAndRetryAsync(policyConfigs.RetryCount, _ => TimeSpan.FromMilliseconds(policyConfigs.RetryDelayInMs));
new usages: var httpRetryPolicy = Policy.Handle < HttpRequestException >().Or < TaskCanceledException >().Or < TimeoutRejectedException >().OrResult < HttpResponseMessage >(RetryRequired).WaitAndRetryAsync(GetBackOff(maxRetries));
new usages: var retryAfterPolicy = Policy.HandleResult < HttpResponseMessage >(ContainsRetryAfterHeader).WaitAndRetryAsync(maxRetries, sleepDurationProvider,(outcome, timespan, retryCount, context) => Task.CompletedTask);
new usages: var retryPolicy = HandleResult().Or < TimeoutRejectedException >().WaitAndRetryAsync(retryCount, retryAttempt => retryDelay);
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(6, attempt => TimeSpan.FromSeconds(0.1 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => { Console.WriteLine($"{exception.Message} : Auto delay for {calculatedWaitDuration.TotalMilliseconds}ms"); });
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(20, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(3, attempt => TimeSpan.FromMilliseconds(500),(exception, calculationWithDuration) => { Console.WriteLine($"Retrying after 200ms: {exception.Message} : {calculationWithDuration}"); });
new usages: AsyncRetryPolicy < HttpResponseMessage > retryAndSleepPolicy = Policy.HandleResult < HttpResponseMessage >(r => ShoulRetryOnHttpResponse(r)).WaitAndRetryAsync(retryCount : retryConfiguration.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(retryConfiguration.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryAttempt, context) => { logger.Info($"Retry Attempt: {retryAttempt}"); await Task.CompletedTask; });
new usages: var retryAndSleepPolicy = Policy.HandleResult < Response >(response => ! this.condition(response)).WaitAndRetryAsync(retryCount : waiterConfig.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(waiterConfig.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryCount, context) => { logger.Trace($"Retry Attempt: {retryCount}"); await Task.CompletedTask; });
new usages: var retry = Policy.Handle < Exception >().WaitAndRetryAsync(Backoff.LinearBackoff(TimeSpan.FromSeconds(settings.RetryInitialDelaySeconds), settings.RetryCount),(exception, span, retryCount, context) => { logger.LogError(exception, "{@EventType} {@Realm} {@TimeSpan} {@retryCount}", "Retry", description, span, retryCount); });
new usages: var policy = Policy.Handle < Exception >().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) },(exception, timeSpan, retryCount, context) => { });
new usages: var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(retryCount : retries, sleepDurationProvider : x => TimeSpan.FromSeconds(5), onRetry :(exception, timeSpan, retry, context) => { logger.LogWarning(exception, "[{prefix}] Exception {ExceptionType} with message {Message} detected on attempt {retry} of {retries}", prefix, exception.GetType().Name, exception.Message, retry, retries); });
new usages: IAsyncPolicy < HttpResponseMessage > policy = Policy.Handle < SocketException >().OrTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var retryWhenServiceUnavailable = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.ServiceUnavailable).WaitAndRetryAsync(1, retryAttempt => TimeSpan.FromSeconds(10));
new usages: var retryWhenTimeout = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.RequestTimeout).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(5));
new usages: var retryWhenThrottling = Policy.HandleResult < HttpResponseMessage >(r => r.StatusCode == HttpStatusCode.TooManyRequests).WaitAndRetryAsync(2, retryAttempt => TimeSpan.FromSeconds(Math.Pow(5, retryAttempt)));
new usages: var retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
new usages: var retry = Policy < HttpResponseMessage >.Handle < Exception >().WaitAndRetryAsync(3, i => TimeSpan.FromSeconds(1));
new usages: var policy = Policy.Handle < InvalidOperationException >().Or < Exception >().WaitAndRetryAsync(_retryCount, retryAttempt => TimeSpan.FromSeconds(1),(ex, time) => { _logger.LogWarning(ex.ToString()); });
new usages: var policy = Policy.Handle < SqlException >().WaitAndRetryAsync(3, i => TimeSpan.FromSeconds(1));
new usages: AsyncRetryPolicy < HttpResponseMessage > retryAndSleepPolicy = Policy.HandleResult < HttpResponseMessage >(r => ShoulRetryOnHttpResponse(r)).WaitAndRetryAsync(retryCount : retryConfiguration.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(retryConfiguration.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryAttempt, context) => { logger.Info($"Retry Attempt: {retryAttempt}"); await Task.CompletedTask.ConfigureAwait(false); });
new usages: var retryAndSleepPolicy = Policy.HandleResult < Response >(response => ! this.condition(response)).WaitAndRetryAsync(retryCount : waiterConfig.MaxAttempts, sleepDurationProvider :(retryCount, response, context) => TimeSpan.FromSeconds(waiterConfig.GetNextDelayInSeconds(retryCount)), onRetryAsync : async(response, timespan, retryCount, context) => { logger.Trace($"Retry Attempt: {retryCount}"); await Task.CompletedTask.ConfigureAwait(false); });
new usages: var policyRetry = Policy.Handle < InvalidOperationException >().WaitAndRetryAsync(3, retryTimespan => TimeSpan.FromSeconds(Math.Pow(2, retryTimespan)),(exception, timespan, retryCount, context) => { var msg = $"第 {retryCount} 次进行错误重试 " + $"of {context.PolicyKey}" + $"at {context.OperationKey}, " + $"due to: {exception}."; _logger.LogWarning(msg); _logger.LogDebug(msg); });
new usages: var waitAndRetryPolicy = Policy.Handle < Exception >().OrResult < HttpResponseMessage >(e => HttpStatusCodeWorthRetry.ToList().Contains((int) e.StatusCode)).WaitAndRetryAsync(MaxRetryCount, attempt => TimeSpan.FromSeconds(1 * Math.Pow(2, attempt)),(exception, calculatedWaitDuration) => PolicyLog($"API is throttling our requests automatically delaying for {calculatedWaitDuration.TotalMilliseconds}ms"));
new usages: var policy = Policy.Handle < Exception >().OrResult < HttpResponseMessage >(r => ! r.IsSuccessStatusCode).WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) + TimeSpan.FromMilliseconds(1000));
new usages: AsyncRetryPolicy retryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)));
new usages: var polly = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, pause => TimeSpan.FromSeconds(5));
new usages: var policy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r => r.StatusCode != HttpStatusCode.OK).WaitAndRetryAsync(_appSettings.RetryAttempt, retryAttempt => TimeSpan.FromMilliseconds(3000));
new usages: var retryPolicy = Policy.HandleResult < IRestResponse >(x => FindWarning(x) is null && x.StatusCode != HttpStatusCode.NotFound && x.StatusCode != HttpStatusCode.Unauthorized && x.StatusCode != HttpStatusCode.Conflict && x.StatusCode != HttpStatusCode.BadRequest && x.StatusCode != HttpStatusCode.OK).WaitAndRetryAsync(retryNumber, retryAttempt => TimeSpan.FromSeconds(retrySleepSeconds));
new usages: var retry = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10), },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Trying for the {retryCount} time!"); Console.ForegroundColor = ConsoleColor.White; });
new usages: var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, x => TimeSpan.FromSeconds(1),(result, span) => { });
new usages: var policy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, x => TimeSpan.FromSeconds(1),(result, span) => { });
new usages: var retryPolicy = Policy.HandleResult < HttpResponseMessage >(r => ! r.IsSuccessStatusCode).WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(1),(result, span, retryCount, ctx) => { Console.WriteLine($"Retrying({retryCount})..."); });
new usages: var retryPolicy = Policy.Handle < HttpRequestException >().Or < Exception >().OrResult < HttpResponseMessage >(res => { return res.StatusCode != System.Net.HttpStatusCode.OK; }).WaitAndRetryAsync(sleepDurations : new[] { TimeSpan.FromMilliseconds(100), TimeSpan.FromMilliseconds(200), TimeSpan.FromMilliseconds(300) }, onRetry :(exception, ts, context) => { Console.WriteLine($"polly.retry：exMsg={exception.Exception ?.Message}, {ts.Minutes * 60 + ts.Seconds}"); });
new usages: var retryWaitPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(5), TimeSpan.FromSeconds(10) },(outcome, timespan, retryCount, context) => { Console.ForegroundColor = ConsoleColor.Blue; Console.WriteLine($"Tentando pela {retryCount} vez!"); Console.ForegroundColor = ConsoleColor.White; });
new usages: var retryPolicy = Policy.Handle < HttpRequestException >().Or < TimeoutException >().Or < TimeoutRejectedException >().WaitAndRetryAsync(retryCount : 2, sleepDurationProvider : retryAttempt => { var waitSeconds = TimeSpan.FromSeconds(Math.Pow(2, retryAttempt - 1)); Console.WriteLine(DateTime.Now.ToString() + "-Retry:[" + retryAttempt + "], wait " + waitSeconds + "s!"); return waitSeconds; });
new usages: var policy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(3, retryAttempt => { var waitSeconds = TimeSpan.FromSeconds(Math.Pow(2, retryAttempt - 1)); Console.WriteLine(DateTime.Now.ToString() + "-Retry:[" + retryAttempt + "], wait " + waitSeconds + "s..."); return waitSeconds; });
new usages: var retryPolicy = Policy.Handle < Exception >((ex) => { logger.Log(LogSeverity.Error,(ex.InnerException != null) ? ex.InnerException.Message : ex.Message + "\r\n GetTrendingStocks retry FAILURE"); return !(ex is Polly.CircuitBreaker.BrokenCircuitException); }).WaitAndRetryAsync(_retryCount, x => TimeSpan.FromMilliseconds(_sleepTimeAfterFail));
new usages: var retryPolicy = HttpPolicyExtensions.HandleTransientHttpError().WaitAndRetryAsync(3, retryAttempt => TimeSpan.FromSeconds(retryAttempt));
new usages: var policy = Policy.Handle < SentNotificationException >().WaitAndRetryAsync(_maxRetryAttempts, retryAttempt => TimeSpan.FromSeconds(Math.Pow(3, retryAttempt)));
new usages: var retryPolicy = Policy.Handle < HttpRequestException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
new usages: var retryPolicy = Policy.Handle < HttpRequestException >().OrResult < HttpResponseMessage >(r =>(int) r.StatusCode == 429).WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
new usages: var retryPolicy = Policy.Handle < System.Net.Sockets.SocketException >().WaitAndRetryAsync(maxRetryAttempts, i => pauseBetweenFailures);
old usages: RetryPolicy retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, context) => { _logger.LogWarning(exception, "Retrying to write config"); });
============= Cluster end ==============

Log: Input to synthesize the program:
Log: Policy policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds(), 2.Seconds(), 3.Seconds() },(_, __, context) => contextData = context);
Log: ---------------------
Log: var policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds(), 2.Seconds(), 3.Seconds() },(_, __, context) => contextData = context);
Log: predict is var policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds(), 2.Seconds(), 3.Seconds() },(_, __, context) => capturedContext = context);
Log: output  is var policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds(), 2.Seconds(), 3.Seconds() },(_, __, context) => capturedContext = context);
Log: ----------------------------------------------------
Log: predict is var policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds() },(_, __, context) => contextValue = context["key"].ToString());
Log: output  is var policy = Policy.Handle < DivideByZeroException >().WaitAndRetryAsync(new[] { 1.Seconds() },(_, __, context) => contextValue = context["key"].ToString());
Log: ----------------------------------------------------
Log: old usage is RetryPolicy retryPolicy = Policy.Handle < Exception >().WaitAndRetryAsync(5, retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),(exception, timeSpan, context) => { _logger.LogWarning(exception, "Retrying to write config"); });
Log: predict is null
total correct cases : 2 totalTestCases 2 Successful rate is 1
The successful rate for transforming old usages: 0 / 1
